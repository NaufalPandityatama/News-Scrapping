{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2c97fd20",
            "metadata": {},
            "source": [
                "# Use \"base\" Kernel for this Notebook"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cnn-step1-intro",
            "metadata": {},
            "source": [
                "### Step 1: CNN Classification with K-Fold and SMOTE Balancing\n",
                "\n",
                "This notebook implements a CNN architecture for text classification and compares three experimental setups:\n",
                "1. **Baseline CNN**: Standard train-test split (Without K-Fold).\n",
                "2. **K-Fold CNN**: 5-Fold Cross-Validation for a more robust evaluation.\n",
                "3. **SMOTE + K-Fold CNN**: Balancing the dataset using SMOTE to handle class imbalance before performing 5-Fold Cross-Validation.\n",
                "\n",
                "Architecture:\n",
                "* **Tokenizer**: Converts text into sequences.\n",
                "* **Embedding Layer**: Dense vector representations.\n",
                "* **Conv1D**: Local pattern detection.\n",
                "* **GlobalMaxPooling1D**: Feature extraction."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "cnn-imports",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data Shape: (2791, 3)\n",
                        "Class Distribution:\n",
                        " label_encoded\n",
                        "1    1331\n",
                        "0    1026\n",
                        "2     434\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.preprocessing.text import Tokenizer\n",
                "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout, LeakyReLU\n",
                "from sklearn.model_selection import train_test_split, KFold\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
                "from imblearn.over_sampling import SMOTE\n",
                "from IPython.display import display\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Load Data\n",
                "df = pd.read_csv('(A) Data/(A) PreProcessed_News Content Title_3000 Data.csv', usecols=['Detokenized', 'Labelling'], engine='python')\n",
                "df = df.dropna()\n",
                "\n",
                "# Map labels to 0, 1, 2\n",
                "label_mapping = {-1: 0, 0: 1, 1: 2}\n",
                "df['label_encoded'] = df['Labelling'].map(label_mapping)\n",
                "\n",
                "X = df['Detokenized'].values\n",
                "y = df['label_encoded'].values\n",
                "\n",
                "print(f\"Data Shape: {df.shape}\")\n",
                "print(\"Class Distribution:\\n\", df['label_encoded'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cnn-preprocessing",
            "metadata": {},
            "source": [
                "### 1. Sequence Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cnn-tokenization",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 6142 unique tokens.\n"
                    ]
                }
            ],
            "source": [
                "# Hyperparameters\n",
                "vocab_size = 5000   # Keep the Top 5,000 Most Frequent Words\n",
                "embedding_dim = 100\n",
                "max_length = 100\n",
                "oov_tok = \"<OOV>\"   # For Handling Words not in the vocabulary\n",
                "\n",
                "# Initialize Tokenizer\n",
                "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
                "tokenizer.fit_on_texts(X)\n",
                "\n",
                "# Convert to Sequences and Pad\n",
                "sequences = tokenizer.texts_to_sequences(X)\n",
                "padded_X = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
                "\n",
                "print(f\"Found {len(tokenizer.word_index)} unique tokens.\")\n",
                "# \"Found 6142 unique tokens, Words ranked 5001 to 6142 are treated as Out of Vocabulary (OOV)\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "model-def-section",
            "metadata": {},
            "source": [
                "### 2. Model Definition\n",
                "We define architectures for both standard and advanced CNN models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "971c25d8",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_model():\n",
                "    model = Sequential([\n",
                "        Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
                "        Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
                "        GlobalMaxPooling1D(),\n",
                "        Dense(24, activation='relu'),\n",
                "        Dropout(0.5),\n",
                "        Dense(3, activation='softmax')\n",
                "    ])\n",
                "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
                "    return model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cnn-model-func",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_advanced_model():\n",
                "    model = Sequential([\n",
                "        Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
                "        Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
                "        GlobalMaxPooling1D(),\n",
                "        \n",
                "        # Deeper Dense Network\n",
                "        Dense(128),\n",
                "        LeakyReLU(alpha=0.1),\n",
                "        Dropout(0.4),\n",
                "        \n",
                "        Dense(64),\n",
                "        LeakyReLU(alpha=0.1),\n",
                "        Dropout(0.4),\n",
                "        \n",
                "        Dense(32),\n",
                "        LeakyReLU(alpha=0.1),\n",
                "        \n",
                "        Dense(3, activation='softmax')\n",
                "    ])\n",
                "    \n",
                "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
                "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
                "    return model"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "baseline-section",
            "metadata": {},
            "source": [
                "### 3. Experiment 1: CNN Without K-Fold Validation\n",
                "Using a standard 80/20 train-test split."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cnn-baseline-run",
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(padded_X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "print(\"Training Baseline Model...\")\n",
                "baseline_model = create_model()\n",
                "baseline_model.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
                "\n",
                "y_pred = np.argmax(baseline_model.predict(X_test), axis=1)\n",
                "baseline_report = classification_report(y_test, y_pred, output_dict=True)\n",
                "print(\"\\nBaseline Classification Report (Without K-Fold):\")\n",
                "print(classification_report(y_test, y_pred))\n",
                "baseline_acc = accuracy_score(y_test, y_pred)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "kfold-section",
            "metadata": {},
            "source": [
                "### 4. Experiment 2: CNN With K-Fold Validation\n",
                "Using 5-Fold Cross-Validation on the original imbalanced dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cnn-kfold-run",
            "metadata": {},
            "outputs": [],
            "source": [
                "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
                "results_list = []\n",
                "fold_no = 1\n",
                "\n",
                "for train, test in kfold.split(padded_X, y):\n",
                "    print(f'Training fold {fold_no}...')\n",
                "    model = create_model()\n",
                "    model.fit(padded_X[train], y[train], epochs=15, batch_size=32, verbose=0)\n",
                "    \n",
                "    y_pred = np.argmax(model.predict(padded_X[test]), axis=1)\n",
                "    report = classification_report(y[test], y_pred, output_dict=True, labels=[0, 1, 2])\n",
                "    \n",
                "    results_list.append({\n",
                "        'Fold': f'Group {fold_no}',\n",
                "        'Accuracy': accuracy_score(y[test], y_pred),\n",
                "        'Prec Class 0': report['0']['precision'],\n",
                "        'Prec Class 1': report['1']['precision'],\n",
                "        'Prec Class 2': report['2']['precision'],\n",
                "        'Recall Class 0': report['0']['recall'],\n",
                "        'Recall Class 1': report['1']['recall'],\n",
                "        'Recall Class 2': report['2']['recall'],\n",
                "        'F1 Class 0': report['0']['f1-score'],\n",
                "        'F1 Class 1': report['1']['f1-score'],\n",
                "        'F1 Class 2': report['2']['f1-score']\n",
                "    })\n",
                "    fold_no += 1\n",
                "\n",
                "results_df = pd.DataFrame(results_list).set_index('Fold')\n",
                "final_kfold_table = pd.concat([results_df, pd.DataFrame({'Average': results_df.mean()}).T])\n",
                "\n",
                "print(\"\\nExperiment 2: K-Fold Results (Imbalanced Data):\")\n",
                "display(final_kfold_table.style.format(\"{:.4f}\"))\n",
                "exp2_avg_acc = results_df['Accuracy'].mean()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "smote-kfold-section",
            "metadata": {},
            "source": [
                "### 5. Experiment 3: Advanced CNN + SMOTE + K-Fold Validation\n",
                "Applying SMOTE to balance data within each fold using the **Advanced CNN Architecture**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cnn-smote-kfold-run",
            "metadata": {},
            "outputs": [],
            "source": [
                "smote = SMOTE(random_state=42)\n",
                "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
                "smote_results_list = []\n",
                "fold_no = 1\n",
                "\n",
                "for train, test in kfold.split(padded_X, y):\n",
                "    print(f'Training fold {fold_no} (Advanced Model + SMOTE)...')\n",
                "    X_train_fold, y_train_fold = padded_X[train], y[train]\n",
                "    X_train_res, y_train_res = smote.fit_resample(X_train_fold, y_train_fold)\n",
                "    \n",
                "    model = create_advanced_model()\n",
                "    model.fit(X_train_res, y_train_res, epochs=20, batch_size=32, verbose=0)\n",
                "    \n",
                "    y_pred = np.argmax(model.predict(padded_X[test]), axis=1)\n",
                "    report = classification_report(y[test], y_pred, output_dict=True, labels=[0, 1, 2])\n",
                "    \n",
                "    smote_results_list.append({\n",
                "        'Fold': f'Group {fold_no}',\n",
                "        'Accuracy': accuracy_score(y[test], y_pred),\n",
                "        'Prec Class 0': report['0']['precision'],\n",
                "        'Prec Class 1': report['1']['precision'],\n",
                "        'Prec Class 2': report['2']['precision'],\n",
                "        'Recall Class 0': report['0']['recall'],\n",
                "        'Recall Class 1': report['1']['recall'],\n",
                "        'Recall Class 2': report['2']['recall'],\n",
                "        'F1 Class 0': report['0']['f1-score'],\n",
                "        'F1 Class 1': report['1']['f1-score'],\n",
                "        'F1 Class 2': report['2']['f1-score']\n",
                "    })\n",
                "    fold_no += 1\n",
                "\n",
                "smote_results_df = pd.DataFrame(smote_results_list).set_index('Fold')\n",
                "final_smote_table = pd.concat([smote_results_df, pd.DataFrame({'Average': smote_results_df.mean()}).T])\n",
                "\n",
                "print(\"\\nExperiment 3: Advanced CNN + SMOTE + K-Fold Results:\")\n",
                "display(final_smote_table.style.format(\"{:.4f}\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "visualization-section",
            "metadata": {},
            "source": [
                "### 6. Results Visualization and Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "comparison-plot",
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "# --- 1. Overall Accuracy Comparison ---\n",
                "exp_names = ['Exp 1: Baseline', 'Exp 2: K-Fold Imbalanced', 'Exp 3: SMOTE + K-Fold (Adv)']\n",
                "accuracies = [\n",
                "    baseline_acc, \n",
                "    results_df['Accuracy'].mean(), \n",
                "    smote_results_df['Accuracy'].mean()\n",
                "]\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "bars = plt.bar(exp_names, accuracies, color=['#3498db', '#e67e22', '#2ecc71'], alpha=0.8)\n",
                "plt.ylabel('Overall Accuracy', fontsize=12, fontweight='bold')\n",
                "plt.title('Overall Accuracy Comparison Across Experiments', fontsize=14, fontweight='bold')\n",
                "plt.ylim(0, 1.0)\n",
                "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
                "\n",
                "for bar in bars:\n",
                "    yval = bar.get_height()\n",
                "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.02, f'{yval:.4f}', ha='center', va='bottom', fontweight='bold')\n",
                "\n",
                "plt.show()\n",
                "\n",
                "# --- 2. Class-wise Recall Comparison ---\n",
                "classes = ['Class 0', 'Class 1', 'Class 2']\n",
                "\n",
                "exp1_recalls = [baseline_report['0']['recall'], baseline_report['1']['recall'], baseline_report['2']['recall']]\n",
                "exp2_recalls = [results_df['Recall Class 0'].mean(), results_df['Recall Class 1'].mean(), results_df['Recall Class 2'].mean()]\n",
                "exp3_recalls = [smote_results_df['Recall Class 0'].mean(), smote_results_df['Recall Class 1'].mean(), smote_results_df['Recall Class 2'].mean()]\n",
                "\n",
                "x = np.arange(len(classes))\n",
                "width = 0.25\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(12, 7))\n",
                "rects1 = ax.bar(x - width, exp1_recalls, width, label='Exp 1: Baseline', color='#3498db', alpha=0.8)\n",
                "rects2 = ax.bar(x, exp2_recalls, width, label='Exp 2: K-Fold Imbalanced', color='#e67e22', alpha=0.8)\n",
                "rects3 = ax.bar(x + width, exp3_recalls, width, label='Exp 3: SMOTE + K-Fold (Adv)', color='#2ecc71', alpha=0.8)\n",
                "\n",
                "ax.set_ylabel('Recall (Accuracy per Class)', fontsize=12, fontweight='bold')\n",
                "ax.set_title('Class-wise Recall Comparison', fontsize=14, fontweight='bold', pad=20)\n",
                "ax.set_xticks(x)\n",
                "ax.set_xticklabels(classes, fontsize=11)\n",
                "ax.legend(loc='upper right', frameon=True, shadow=True)\n",
                "ax.set_ylim(0, 1.0)\n",
                "ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
                "\n",
                "def autolabel_recall(rects):\n",
                "    for rect in rects:\n",
                "        height = rect.get_height()\n",
                "        ax.annotate(f'{height:.2f}', \n",
                "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
                "                    xytext=(0, 3), textcoords=\"offset points\",\n",
                "                    ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
                "\n",
                "autolabel_recall(rects1)\n",
                "autolabel_recall(rects2)\n",
                "autolabel_recall(rects3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}