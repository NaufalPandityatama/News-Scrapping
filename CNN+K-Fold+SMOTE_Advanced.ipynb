{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "83e84143",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use \"Base\" Kernel for this notebook"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "### Advanced CNN Classification with Deep Layers and Alternative Activations\n",
                "\n",
                "This notebook explores an enhanced CNN architecture for text classification. Compared to the previous experiment, this model includes:\n",
                "1. **More Dense Layers**: Increased depth to capture more complex patterns.\n",
                "2. **Alternative Activation Functions**: Using `LeakyReLU` instead of standard `ReLU` to prevent the vanishing gradient problem (dead neurons).\n",
                "3. **Higher Dropout**: To prevent overfitting in deeper layers.\n",
                "4. **K-Fold and SMOTE**: Maintaining robust evaluation and balancing techniques."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "imports",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data Shape: (2791, 3)\n",
                        "Class Distribution:\n",
                        " label_encoded\n",
                        "1    1331\n",
                        "0    1026\n",
                        "2     434\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.preprocessing.text import Tokenizer\n",
                "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout, LeakyReLU\n",
                "from sklearn.model_selection import train_test_split, KFold\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
                "from imblearn.over_sampling import SMOTE\n",
                "from IPython.display import display\n",
                "\n",
                "# Load Data\n",
                "file_path = '(A) Data/(A) PreProcessed_News Content Title_3000 Data.csv'\n",
                "df = pd.read_csv(file_path, usecols=['Detokenized', 'Labelling'], engine='python')\n",
                "df = df.dropna()\n",
                "\n",
                "# Map labels to 0, 1, 2\n",
                "label_mapping = {-1: 0, 0: 1, 1: 2}\n",
                "df['label_encoded'] = df['Labelling'].map(label_mapping)\n",
                "\n",
                "X = df['Detokenized'].values\n",
                "y = df['label_encoded'].values\n",
                "\n",
                "print(f\"Data Shape: {df.shape}\")\n",
                "print(\"Class Distribution:\\n\", df['label_encoded'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "preprocessing",
            "metadata": {},
            "source": [
                "### 1. Sequence Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "tokenization",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 6142 unique tokens.\n"
                    ]
                }
            ],
            "source": [
                "# Hyperparameters\n",
                "vocab_size = 5000\n",
                "embedding_dim = 100\n",
                "max_length = 100\n",
                "oov_tok = \"<OOV>\"\n",
                "\n",
                "# Initialize Tokenizer\n",
                "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
                "tokenizer.fit_on_texts(X)\n",
                "\n",
                "# Convert to Sequences and Pad\n",
                "sequences = tokenizer.texts_to_sequences(X)\n",
                "padded_X = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
                "\n",
                "print(f\"Found {len(tokenizer.word_index)} unique tokens.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "model-def",
            "metadata": {},
            "source": [
                "### 2. Advanced Model Definition\n",
                "We use a deeper architecture with `LeakyReLU` activation and multiple Dense layers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "advanced-model",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model: \"sequential\"\n",
                        "_________________________________________________________________\n",
                        " Layer (type)                Output Shape              Param #   \n",
                        "=================================================================\n",
                        " embedding (Embedding)       (None, 100, 100)          500000    \n",
                        "                                                                 \n",
                        " conv1d (Conv1D)             (None, 96, 128)           64128     \n",
                        "                                                                 \n",
                        " global_max_pooling1d (Globa  (None, 128)              0         \n",
                        " lMaxPooling1D)                                                  \n",
                        "                                                                 \n",
                        " dense (Dense)               (None, 128)               16512     \n",
                        "                                                                 \n",
                        " leaky_re_lu (LeakyReLU)     (None, 128)               0         \n",
                        "                                                                 \n",
                        " dropout (Dropout)           (None, 128)               0         \n",
                        "                                                                 \n",
                        " dense_1 (Dense)             (None, 64)                8256      \n",
                        "                                                                 \n",
                        " leaky_re_lu_1 (LeakyReLU)   (None, 64)                0         \n",
                        "                                                                 \n",
                        " dropout_1 (Dropout)         (None, 64)                0         \n",
                        "                                                                 \n",
                        " dense_2 (Dense)             (None, 32)                2080      \n",
                        "                                                                 \n",
                        " leaky_re_lu_2 (LeakyReLU)   (None, 32)                0         \n",
                        "                                                                 \n",
                        " dense_3 (Dense)             (None, 3)                 99        \n",
                        "                                                                 \n",
                        "=================================================================\n",
                        "Total params: 591,075\n",
                        "Trainable params: 591,075\n",
                        "Non-trainable params: 0\n",
                        "_________________________________________________________________\n"
                    ]
                }
            ],
            "source": [
                "def create_advanced_model():\n",
                "    model = Sequential([\n",
                "        Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
                "        Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
                "        GlobalMaxPooling1D(),\n",
                "        \n",
                "        # Deeper Dense Network\n",
                "        Dense(128),\n",
                "        LeakyReLU(alpha=0.1),\n",
                "        Dropout(0.4),\n",
                "        \n",
                "        Dense(64),\n",
                "        LeakyReLU(alpha=0.1),\n",
                "        Dropout(0.4),\n",
                "        \n",
                "        Dense(32),\n",
                "        LeakyReLU(alpha=0.1),\n",
                "        \n",
                "        Dense(3, activation='softmax')\n",
                "    ])\n",
                "    \n",
                "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
                "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
                "    return model\n",
                "\n",
                "model_summary = create_advanced_model()\n",
                "model_summary.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "experiment-section",
            "metadata": {},
            "source": [
                "### 3. Experiment: Advanced CNN + SMOTE + K-Fold Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "run-experiment",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training fold 1 (Advanced Model + SMOTE)...\n",
                        "18/18 [==============================] - 0s 3ms/step\n",
                        "Training fold 2 (Advanced Model + SMOTE)...\n",
                        "18/18 [==============================] - 0s 3ms/step\n",
                        "Training fold 3 (Advanced Model + SMOTE)...\n",
                        "18/18 [==============================] - 0s 3ms/step\n",
                        "Training fold 4 (Advanced Model + SMOTE)...\n",
                        "18/18 [==============================] - 0s 3ms/step\n",
                        "Training fold 5 (Advanced Model + SMOTE)...\n",
                        "18/18 [==============================] - 0s 4ms/step\n",
                        "\n",
                        "Advanced Experiment Results (Deep CNN + LeakyReLU + SMOTE + K-Fold):\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<style type=\"text/css\">\n",
                            "</style>\n",
                            "<table id=\"T_ad6e0\">\n",
                            "  <thead>\n",
                            "    <tr>\n",
                            "      <th class=\"blank level0\" >&nbsp;</th>\n",
                            "      <th id=\"T_ad6e0_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
                            "      <th id=\"T_ad6e0_level0_col1\" class=\"col_heading level0 col1\" >Prec Class 0</th>\n",
                            "      <th id=\"T_ad6e0_level0_col2\" class=\"col_heading level0 col2\" >Prec Class 1</th>\n",
                            "      <th id=\"T_ad6e0_level0_col3\" class=\"col_heading level0 col3\" >Prec Class 2</th>\n",
                            "      <th id=\"T_ad6e0_level0_col4\" class=\"col_heading level0 col4\" >Recall Class 0</th>\n",
                            "      <th id=\"T_ad6e0_level0_col5\" class=\"col_heading level0 col5\" >Recall Class 1</th>\n",
                            "      <th id=\"T_ad6e0_level0_col6\" class=\"col_heading level0 col6\" >Recall Class 2</th>\n",
                            "      <th id=\"T_ad6e0_level0_col7\" class=\"col_heading level0 col7\" >F1 Class 0</th>\n",
                            "      <th id=\"T_ad6e0_level0_col8\" class=\"col_heading level0 col8\" >F1 Class 1</th>\n",
                            "      <th id=\"T_ad6e0_level0_col9\" class=\"col_heading level0 col9\" >F1 Class 2</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th id=\"T_ad6e0_level0_row0\" class=\"row_heading level0 row0\" >Group 1</th>\n",
                            "      <td id=\"T_ad6e0_row0_col0\" class=\"data row0 col0\" >0.5921</td>\n",
                            "      <td id=\"T_ad6e0_row0_col1\" class=\"data row0 col1\" >0.6683</td>\n",
                            "      <td id=\"T_ad6e0_row0_col2\" class=\"data row0 col2\" >0.7202</td>\n",
                            "      <td id=\"T_ad6e0_row0_col3\" class=\"data row0 col3\" >0.3354</td>\n",
                            "      <td id=\"T_ad6e0_row0_col4\" class=\"data row0 col4\" >0.6814</td>\n",
                            "      <td id=\"T_ad6e0_row0_col5\" class=\"data row0 col5\" >0.5092</td>\n",
                            "      <td id=\"T_ad6e0_row0_col6\" class=\"data row0 col6\" >0.6463</td>\n",
                            "      <td id=\"T_ad6e0_row0_col7\" class=\"data row0 col7\" >0.6748</td>\n",
                            "      <td id=\"T_ad6e0_row0_col8\" class=\"data row0 col8\" >0.5966</td>\n",
                            "      <td id=\"T_ad6e0_row0_col9\" class=\"data row0 col9\" >0.4417</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_ad6e0_level0_row1\" class=\"row_heading level0 row1\" >Group 2</th>\n",
                            "      <td id=\"T_ad6e0_row1_col0\" class=\"data row1 col0\" >0.6344</td>\n",
                            "      <td id=\"T_ad6e0_row1_col1\" class=\"data row1 col1\" >0.6481</td>\n",
                            "      <td id=\"T_ad6e0_row1_col2\" class=\"data row1 col2\" >0.7174</td>\n",
                            "      <td id=\"T_ad6e0_row1_col3\" class=\"data row1 col3\" >0.4375</td>\n",
                            "      <td id=\"T_ad6e0_row1_col4\" class=\"data row1 col4\" >0.7330</td>\n",
                            "      <td id=\"T_ad6e0_row1_col5\" class=\"data row1 col5\" >0.6066</td>\n",
                            "      <td id=\"T_ad6e0_row1_col6\" class=\"data row1 col6\" >0.5158</td>\n",
                            "      <td id=\"T_ad6e0_row1_col7\" class=\"data row1 col7\" >0.6880</td>\n",
                            "      <td id=\"T_ad6e0_row1_col8\" class=\"data row1 col8\" >0.6574</td>\n",
                            "      <td id=\"T_ad6e0_row1_col9\" class=\"data row1 col9\" >0.4734</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_ad6e0_level0_row2\" class=\"row_heading level0 row2\" >Group 3</th>\n",
                            "      <td id=\"T_ad6e0_row2_col0\" class=\"data row2 col0\" >0.5932</td>\n",
                            "      <td id=\"T_ad6e0_row2_col1\" class=\"data row2 col1\" >0.6919</td>\n",
                            "      <td id=\"T_ad6e0_row2_col2\" class=\"data row2 col2\" >0.6942</td>\n",
                            "      <td id=\"T_ad6e0_row2_col3\" class=\"data row2 col3\" >0.3312</td>\n",
                            "      <td id=\"T_ad6e0_row2_col4\" class=\"data row2 col4\" >0.6493</td>\n",
                            "      <td id=\"T_ad6e0_row2_col5\" class=\"data row2 col5\" >0.5316</td>\n",
                            "      <td id=\"T_ad6e0_row2_col6\" class=\"data row2 col6\" >0.6538</td>\n",
                            "      <td id=\"T_ad6e0_row2_col7\" class=\"data row2 col7\" >0.6699</td>\n",
                            "      <td id=\"T_ad6e0_row2_col8\" class=\"data row2 col8\" >0.6021</td>\n",
                            "      <td id=\"T_ad6e0_row2_col9\" class=\"data row2 col9\" >0.4397</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_ad6e0_level0_row3\" class=\"row_heading level0 row3\" >Group 4</th>\n",
                            "      <td id=\"T_ad6e0_row3_col0\" class=\"data row3 col0\" >0.5896</td>\n",
                            "      <td id=\"T_ad6e0_row3_col1\" class=\"data row3 col1\" >0.6376</td>\n",
                            "      <td id=\"T_ad6e0_row3_col2\" class=\"data row3 col2\" >0.7219</td>\n",
                            "      <td id=\"T_ad6e0_row3_col3\" class=\"data row3 col3\" >0.3380</td>\n",
                            "      <td id=\"T_ad6e0_row3_col4\" class=\"data row3 col4\" >0.6919</td>\n",
                            "      <td id=\"T_ad6e0_row3_col5\" class=\"data row3 col5\" >0.5056</td>\n",
                            "      <td id=\"T_ad6e0_row3_col6\" class=\"data row3 col6\" >0.6000</td>\n",
                            "      <td id=\"T_ad6e0_row3_col7\" class=\"data row3 col7\" >0.6636</td>\n",
                            "      <td id=\"T_ad6e0_row3_col8\" class=\"data row3 col8\" >0.5947</td>\n",
                            "      <td id=\"T_ad6e0_row3_col9\" class=\"data row3 col9\" >0.4324</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_ad6e0_level0_row4\" class=\"row_heading level0 row4\" >Group 5</th>\n",
                            "      <td id=\"T_ad6e0_row4_col0\" class=\"data row4 col0\" >0.5932</td>\n",
                            "      <td id=\"T_ad6e0_row4_col1\" class=\"data row4 col1\" >0.7041</td>\n",
                            "      <td id=\"T_ad6e0_row4_col2\" class=\"data row4 col2\" >0.7053</td>\n",
                            "      <td id=\"T_ad6e0_row4_col3\" class=\"data row4 col3\" >0.3430</td>\n",
                            "      <td id=\"T_ad6e0_row4_col4\" class=\"data row4 col4\" >0.6603</td>\n",
                            "      <td id=\"T_ad6e0_row4_col5\" class=\"data row4 col5\" >0.5360</td>\n",
                            "      <td id=\"T_ad6e0_row4_col6\" class=\"data row4 col6\" >0.5960</td>\n",
                            "      <td id=\"T_ad6e0_row4_col7\" class=\"data row4 col7\" >0.6815</td>\n",
                            "      <td id=\"T_ad6e0_row4_col8\" class=\"data row4 col8\" >0.6091</td>\n",
                            "      <td id=\"T_ad6e0_row4_col9\" class=\"data row4 col9\" >0.4354</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_ad6e0_level0_row5\" class=\"row_heading level0 row5\" >Max</th>\n",
                            "      <td id=\"T_ad6e0_row5_col0\" class=\"data row5 col0\" >0.6344</td>\n",
                            "      <td id=\"T_ad6e0_row5_col1\" class=\"data row5 col1\" >0.7041</td>\n",
                            "      <td id=\"T_ad6e0_row5_col2\" class=\"data row5 col2\" >0.7219</td>\n",
                            "      <td id=\"T_ad6e0_row5_col3\" class=\"data row5 col3\" >0.4375</td>\n",
                            "      <td id=\"T_ad6e0_row5_col4\" class=\"data row5 col4\" >0.7330</td>\n",
                            "      <td id=\"T_ad6e0_row5_col5\" class=\"data row5 col5\" >0.6066</td>\n",
                            "      <td id=\"T_ad6e0_row5_col6\" class=\"data row5 col6\" >0.6538</td>\n",
                            "      <td id=\"T_ad6e0_row5_col7\" class=\"data row5 col7\" >0.6880</td>\n",
                            "      <td id=\"T_ad6e0_row5_col8\" class=\"data row5 col8\" >0.6574</td>\n",
                            "      <td id=\"T_ad6e0_row5_col9\" class=\"data row5 col9\" >0.4734</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_ad6e0_level0_row6\" class=\"row_heading level0 row6\" >Min</th>\n",
                            "      <td id=\"T_ad6e0_row6_col0\" class=\"data row6 col0\" >0.5896</td>\n",
                            "      <td id=\"T_ad6e0_row6_col1\" class=\"data row6 col1\" >0.6376</td>\n",
                            "      <td id=\"T_ad6e0_row6_col2\" class=\"data row6 col2\" >0.6942</td>\n",
                            "      <td id=\"T_ad6e0_row6_col3\" class=\"data row6 col3\" >0.3312</td>\n",
                            "      <td id=\"T_ad6e0_row6_col4\" class=\"data row6 col4\" >0.6493</td>\n",
                            "      <td id=\"T_ad6e0_row6_col5\" class=\"data row6 col5\" >0.5056</td>\n",
                            "      <td id=\"T_ad6e0_row6_col6\" class=\"data row6 col6\" >0.5158</td>\n",
                            "      <td id=\"T_ad6e0_row6_col7\" class=\"data row6 col7\" >0.6636</td>\n",
                            "      <td id=\"T_ad6e0_row6_col8\" class=\"data row6 col8\" >0.5947</td>\n",
                            "      <td id=\"T_ad6e0_row6_col9\" class=\"data row6 col9\" >0.4324</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_ad6e0_level0_row7\" class=\"row_heading level0 row7\" >Average</th>\n",
                            "      <td id=\"T_ad6e0_row7_col0\" class=\"data row7 col0\" >0.6005</td>\n",
                            "      <td id=\"T_ad6e0_row7_col1\" class=\"data row7 col1\" >0.6700</td>\n",
                            "      <td id=\"T_ad6e0_row7_col2\" class=\"data row7 col2\" >0.7118</td>\n",
                            "      <td id=\"T_ad6e0_row7_col3\" class=\"data row7 col3\" >0.3570</td>\n",
                            "      <td id=\"T_ad6e0_row7_col4\" class=\"data row7 col4\" >0.6832</td>\n",
                            "      <td id=\"T_ad6e0_row7_col5\" class=\"data row7 col5\" >0.5378</td>\n",
                            "      <td id=\"T_ad6e0_row7_col6\" class=\"data row7 col6\" >0.6024</td>\n",
                            "      <td id=\"T_ad6e0_row7_col7\" class=\"data row7 col7\" >0.6756</td>\n",
                            "      <td id=\"T_ad6e0_row7_col8\" class=\"data row7 col8\" >0.6120</td>\n",
                            "      <td id=\"T_ad6e0_row7_col9\" class=\"data row7 col9\" >0.4445</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_ad6e0_level0_row8\" class=\"row_heading level0 row8\" >Stdev</th>\n",
                            "      <td id=\"T_ad6e0_row8_col0\" class=\"data row8 col0\" >0.0190</td>\n",
                            "      <td id=\"T_ad6e0_row8_col1\" class=\"data row8 col1\" >0.0282</td>\n",
                            "      <td id=\"T_ad6e0_row8_col2\" class=\"data row8 col2\" >0.0118</td>\n",
                            "      <td id=\"T_ad6e0_row8_col3\" class=\"data row8 col3\" >0.0452</td>\n",
                            "      <td id=\"T_ad6e0_row8_col4\" class=\"data row8 col4\" >0.0325</td>\n",
                            "      <td id=\"T_ad6e0_row8_col5\" class=\"data row8 col5\" >0.0407</td>\n",
                            "      <td id=\"T_ad6e0_row8_col6\" class=\"data row8 col6\" >0.0551</td>\n",
                            "      <td id=\"T_ad6e0_row8_col7\" class=\"data row8 col7\" >0.0095</td>\n",
                            "      <td id=\"T_ad6e0_row8_col8\" class=\"data row8 col8\" >0.0260</td>\n",
                            "      <td id=\"T_ad6e0_row8_col9\" class=\"data row8 col9\" >0.0166</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "<pandas.io.formats.style.Styler at 0x1485d375580>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "smote = SMOTE(random_state=42)\n",
                "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
                "advanced_results = []\n",
                "fold_no = 1\n",
                "\n",
                "for train, test in kfold.split(padded_X, y):\n",
                "    print(f'Training fold {fold_no} (Advanced Model + SMOTE)...')\n",
                "    \n",
                "    # Apply SMOTE to the TRAINING set\n",
                "    X_train_fold, y_train_fold = padded_X[train], y[train]\n",
                "    X_train_res, y_train_res = smote.fit_resample(X_train_fold, y_train_fold)\n",
                "    \n",
                "    model = create_advanced_model()\n",
                "    # Using slightly more epochs (20) for the deeper model to converge\n",
                "    model.fit(X_train_res, y_train_res, epochs=20, batch_size=32, verbose=0)\n",
                "    \n",
                "    y_pred = np.argmax(model.predict(padded_X[test]), axis=1)\n",
                "    report = classification_report(y[test], y_pred, output_dict=True, labels=[0, 1, 2])\n",
                "    \n",
                "    advanced_results.append({\n",
                "        'Fold': f'Group {fold_no}',\n",
                "        'Accuracy': accuracy_score(y[test], y_pred),\n",
                "        'Prec Class 0': report['0']['precision'],\n",
                "        'Prec Class 1': report['1']['precision'],\n",
                "        'Prec Class 2': report['2']['precision'],\n",
                "        'Recall Class 0': report['0']['recall'],\n",
                "        'Recall Class 1': report['1']['recall'],\n",
                "        'Recall Class 2': report['2']['recall'],\n",
                "        'F1 Class 0': report['0']['f1-score'],\n",
                "        'F1 Class 1': report['1']['f1-score'],\n",
                "        'F1 Class 2': report['2']['f1-score']\n",
                "    })\n",
                "    fold_no += 1\n",
                "\n",
                "results_df = pd.DataFrame(advanced_results).set_index('Fold')\n",
                "summary_stats = pd.DataFrame({\n",
                "    'Max': results_df.max(), \n",
                "    'Min': results_df.min(), \n",
                "    'Average': results_df.mean(), \n",
                "    'Stdev': results_df.std()\n",
                "}).T\n",
                "final_table = pd.concat([results_df, summary_stats])\n",
                "\n",
                "print(\"\\nAdvanced Experiment Results (Deep CNN + LeakyReLU + SMOTE + K-Fold):\")\n",
                "display(final_table.style.format(\"{:.4f}\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "conclusion",
            "metadata": {},
            "source": [
                "### 4. Summary and Interpretation\n",
                "\n",
                "By increasing the number of Dense layers and applying `LeakyReLU`, the model is expected to learn more complex semantic relationships in the text. \n",
                "\n",
                "*   **Dense Layers (128, 64, 32)**: Provide a hierarchy of features from the CNN output.\n",
                "*   **LeakyReLU**: Ensures that neurons that fall into negative territory still contribute to the gradient, helping the model learn better than standard ReLU.\n",
                "*   **Dropout (0.4)**: Crucial for deeper networks to ensure that the model generalizes well to unseen data.\n",
                "\n",
                "Compare the 'Average Accuracy' and 'Recall Class 2' with the previous experiment to validate improvement."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
